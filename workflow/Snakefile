import glob
import os

configfile: "config/config.yml"

samples = {}
for fastq in glob.glob('reads/*/*.fastq.gz'):
    organism = fastq.split('/')[1]
    sample = os.path.basename(fastq)[:-len('.fastq.gz')]
    samples[organism] = samples.get(organism, []) + [sample]

bwa_index_extensions = [".amb", ".ann", ".bwt", ".pac", ".sa"]

wildcard_constraints:
    organism="(pst)|(pgt)",
    existing_samples="(all)|(subset)"

def all_inputs(wildcards):
    inputs = {}
    for organism in samples:
        inputs[f'{organism}_tree'] = f'results/{organism}/trees/{organism}_all.pdf'
        inputs[f'{organism}_report'] = f'results/{organism}/report/{organism}.multiqc.html'
        inputs[f'{organism}_auspice_json'] = f'results/auspice/{organism}_all_auspice.json'
    return inputs

rule all:
    input:
        unpack(all_inputs)

def primer_performance_summaries(wildcards):
    organism = wildcards.organism
    sample = wildcards.sample
    return [
        f"results/{organism}/{sample}/primer_performance/{sample}_primer_performance_by_{groupby}.csv"
        for groupby in config['primer_performance_groups']
        ]

rule create_sample_multiqc_row:
    input:
        tree_input="results/{organism}/{sample}/tree_input/{sample}.ffn",
        primer_performance_summaries=primer_performance_summaries
    output: 
        multiqc_row="results/{organism}/{sample}/multiqc_row/{sample}_multiqc_row.csv"
    log: "logs/{organism}/{sample}/create_sample_multiqc_row_{sample}.log"
    conda: "envs/visualise_tree.yml"
    script: "scripts/create_sample_multiqc_row.py"

rule summarise_primer_performance:
    input:
        primer_performance="results/{organism}/{sample}/primer_performance/{sample}_primer_performance.csv"
    output:
        primer_performance_summary="results/{organism}/{sample}/primer_performance/{sample}_primer_performance_by_{groupby}.csv"
    log: "logs/{organism}/{sample}/summarise_primer_performance_by_{groupby}_{sample}.log"
    conda: "envs/visualise_tree.yml"
    script: "scripts/summarise_primer_performance.py" 

rule cumulative_amplicon_coverage:
    input:
        primer_performance="results/{organism}/{sample}/primer_performance/{sample}_primer_performance.csv"
    output:
        cumulative_amplicon_coverage="results/{organism}/{sample}/primer_performance/{sample}_cumulative_amplicon_coverage.csv"
    log: "logs/{organism}/{sample}/cumulative_amplicon_coverage_{sample}.log"
    conda: "envs/visualise_tree.yml"
    script: "scripts/cumulative_amplicon_coverage.py"

# This is a work around to ensure that multiqc can create the plot specified in
# config/multiqc_config.yaml.
# Unless there is at least one _mqc.yaml in the directory, multiqc will not 
# pick up any of the custom_data specified in the --config file. To ensure it
# does pick up those files, we create a file for each sample with only id.
rule placeholder_mqc:
    output: 
        placeholder_mqc="results/{organism}/{sample}/primer_performance/{sample}_empty_config_required_for_amplicon_coverage_mqc.yaml"
    log: "logs/{organism}/{sample}/placeholder_mqc_{sample}.log"
    script: "scripts/create_empty_config_required_for_amplicon_coverage_mqc.py"

def snp_tables_to_summaries(wildcards):
    organism = wildcards.organism
    return [
        f"results/{organism}/{sample}/snps/{sample}.tsv"
        for sample in samples[organism]
    ]

rule summarise_snps:
    input:
        ref="resources/{organism}/reference/{organism}.fna",
        snps=snp_tables_to_summaries
    output:
        snp_counts="results/{organism}/report/snp_summary.csv"
    log: "logs/{organism}/summarise_snps.log"
    conda: "envs/visualise_tree.yml"
    script: "scripts/summarise_snps_by_gene.py"

rule primer_performance:
    input:
        pileup="results/{organism}/{sample}/aligned/{sample}.pileup.gz",
        primers="resources/{organism}/{organism}_primer_metadata.csv",
        consensus="results/{organism}/{sample}/aligned/{sample}.fna",
    output:
        primer_performance="results/{organism}/{sample}/primer_performance/{sample}_primer_performance.csv"
    log: "logs/{organism}/{sample}/primer_performance_{sample}.log"
    conda: "envs/visualise_tree.yml"
    script: "scripts/primer_performance.py"

rule bwa_index:
    input: "resources/{organism}/reference/{organism}.fna"
    output:
        multiext(
            "resources/{organism}/reference/{organism}.fna",
            *bwa_index_extensions
        )
    conda: "envs/bwa_samtools.yml"
    log: "logs/{organism}/bwa_index.log"
    shell:"bwa index {input} >{log} 2>&1"

rule bwa_mem:
    input:
        ref="resources/{organism}/reference/{organism}.fna",
        idx=multiext(
            "resources/{organism}/reference/{organism}.fna",
            *bwa_index_extensions
        ),
        fastq="results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz",
    output: "results/{organism}/{sample}/aligned/{sample}.bam"
    conda: "envs/bwa_samtools.yml"
    log: "logs/{organism}/{sample}/bwa_mem_{sample}.log"
    threads: config["bwa_mem_threads"]
    shell: """
    (
        bwa mem -t {threads} {input.ref} {input.fastq} | samtools sort > {output}
    ) >{log} 2>&1
    """

rule samtools_index:
    input: "resources/{organism}/reference/{organism}.fna"
    output: "resources/{organism}/reference/{organism}.fna.fai"
    log: "logs/{organism}/samtools_index.log"
    conda: "envs/bwa_samtools.yml"
    shell: "samtools faidx {input} >{output} 2>{log}"

rule filter_reads:
    input: "reads/{organism}/{sample}.fastq.gz"
    output: "results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz"
    log: "logs/{organism}/{sample}/filter_reads_{sample}.log"
    conda: "envs/nanoq.yml"
    shell: """
        nanoq \
            -m {config[maximum_read_length]} \
            -q {config[minimum_average_read_quality]} \
            -i {input} \
            -o {output} \
            >{log} 2>&1
    """

rule fastqc:
    input: "reads/{organism}/{sample}.fastq.gz"
    output:
        html="results/{organism}/{sample}/fastqc/{sample}_fastqc.html",
        data="results/{organism}/{sample}/fastqc/{sample}_fastqc.zip",
    log: "logs/{organism}/{sample}/fastqc_{sample}.log"
    conda: "envs/fastqc.yml"
    shell: "fastqc -o $(dirname {output.html}) {input} >{log} 2>&1"

use rule fastqc as fastqc_filtered_reads with:
    input: "results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz"
    output:
        html="results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.html",
        data="results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.zip"
    log: "logs/{organism}/{sample}/fastqc_filtered_reads_{sample}.log"

rule flagstat:
    input: "results/{organism}/{sample}/aligned/{sample}.bam"
    output: "results/{organism}/{sample}/flagstat/{sample}.txt"
    log: "logs/{organism}/{sample}/flagstat_{sample}.log"
    conda: "envs/bwa_samtools.yml"
    shell: "samtools flagstat {input} >{output} 2>{log}"

def multiqc_input(wildcards):
    organism = wildcards.organism
    files = [
        f"results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.zip"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/flagstat/{sample}.txt"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/primer_performance/{sample}_cumulative_amplicon_coverage.csv"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/primer_performance/{sample}_empty_config_required_for_amplicon_coverage_mqc.yaml"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/multiqc_row/{sample}_multiqc_row.csv"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/report/snp_summary.csv"
    ]
    return files

rule multiqc:
    input: multiqc_input
    output: "results/{organism}/report/{organism}.multiqc.html",
    log: "logs/{organism}/multiqc_{organism}.log",
    conda: "envs/multiqc.yml"
    shell: """
        tempdir=$(mktemp -d)
        cp {input} $tempdir
        multiqc -f $tempdir --config config/multiqc_config.yml -n {output} >{log} 2>&1
        rm -r $tempdir
    """

rule pileup:
    input:
        ref="resources/{organism}/reference/{organism}.fna",
        idx="resources/{organism}/reference/{organism}.fna.fai",
        bam="results/{organism}/{sample}/aligned/{sample}.bam",
    output: "results/{organism}/{sample}/aligned/{sample}.pileup.gz"
    log: "logs/{organism}/{sample}/pileup_{sample}.log"
    conda: "envs/bwa_samtools.yml"
    shell: "(samtools mpileup -f {input.ref} {input.bam} | gzip -c > {output}) >{log} 2>&1"

rule consensus:
    input:
        pileup="results/{organism}/{sample}/aligned/{sample}.pileup.gz",
        ref="resources/{organism}/reference/{organism}.fna",
    output: 
        consensus="results/{organism}/{sample}/aligned/{sample}.fna",
        snps="results/{organism}/{sample}/snps/{sample}.tsv"
    log: "logs/{organism}/{sample}/consensus_{sample}.log"
    conda: "envs/biopython_pandas.yml"
    script: "scripts/pileup_to_consensus.py"

rule extract_cds:
    input: 
        consensus="results/{organism}/{sample}/aligned/{sample}.fna",
        gff="resources/{organism}/reference/{organism}.gff",
    output: "results/{organism}/{sample}/aligned/{sample}.ffn"
    log: "logs/{organism}/{sample}/extract_cds_{sample}.log"
    conda: "envs/gffread.yml"
    shell: "gffread -x {output} -g {input.consensus} {input.gff} >{log} 2>&1"

rule flatten:
    input: "results/{organism}/{sample}/aligned/{sample}.ffn"
    output: "results/{organism}/{sample}/tree_input/{sample}.ffn"
    log: "logs/{organism}/{sample}/flatten_{sample}.log"
    shell: 
        """
        echo \\>{wildcards.sample} > {output}
        grep -v \\> {input} | tr -d '\n' >> {output}
        echo >> {output}
        """

def tree_input_files_to_merge(wildcards):
    organism = wildcards.organism
    return [
        f"results/{organism}/{sample}/tree_input/{sample}.ffn"
        for sample in samples[organism]
    ]

rule merge:
    input:
        existing_samples="resources/{organism}/{organism}_{existing_samples}.ffn.gz",
        new_samples=tree_input_files_to_merge
    output: "results/{organism}/trees/{organism}_{existing_samples}.ffn",
    log: "logs/{organism}/trees/merge_{existing_samples}.log",
    shell:
        """
        (cat {input.new_samples} > {output}
        gunzip -c {input.existing_samples} >> {output}) >{log}
        """

rule tree:
    input: "results/{organism}/trees/{organism}_{existing_samples}.ffn"
    output: "results/{organism}/trees/{organism}_{existing_samples}.nwk"
    log: "logs/{organism}/trees/tree_{existing_samples}.log"
    shell: "workflow/scripts/fasttree.sh {input} {output} >{log} 2>&1"

rule visualise_tree:
    input:
        tree="results/{organism}/trees/{organism}_{existing_samples}.nwk",
        metadata="resources/{organism}/{organism}_sample_metadata.xlsx"
    output: "results/{organism}/trees/{organism}_{existing_samples}.pdf"
    log: "logs/{organism}/trees/visualise_tree_{existing_samples}.log"
    conda: "envs/visualise_tree.yml"
    script: "scripts/visualise_tree.py"

    rule convert_metaxls:
    input:
        metadata="resources/{organism}/{organism}_sample_metadata.xlsx"
    output:
        metadata="resources/{organism}/{organism}_sample_metadata.csv"
    log: "logs/{organism}/nextstrain/ns_convertxls.log"
    shell:
        """
        ssconvert {input.metadata} {output.metadata}
        sed -i-e 's!tree_new_name!strain!g' {output.metadata}
        sed -i-e 's!\"!!g' {output.metadata}
        rm {output.metadata}-e*
        """

rule rename_tree:
    input:
        metadata=rules.convert_metaxls.output.metadata,
        treefna=rules.tree.input,
        treenwk=rules.tree.output
    output:
        mvfna="results/{organism}/trees/auspice/renamed_{organism}_{existing_samples}.ffn",
        mvnwk="results/{organism}/trees/auspice/renamed_{organism}_{existing_samples}.nwk"
    log: "logs/{organism}/nextstrain/ns_rename_{existing_samples}.log"
    shell:
        """
        cp {input.treefna} {output.mvfna}tmp
        cp {input.treenwk} {output.mvnwk}tmp
        while IFS=, read -r old_name new_name _; do
            new=$new_name|cut -d':' -f1
            if grep -Fq $old_name {input.treefna}; then
                echo 'renaming $old_name to $new_name in {input.treefna}'
                sed -i "s!$old_name!$(echo $new_name | cut -d':' -f1)!" {output.mvfna}tmp
            fi
            if grep -Fq "$old_name" {input.treenwk}; then
                echo 'renaming $old_name to $new_name in {input.treenwk}'
                sed -i "s!$old_name!$(echo $new_name | cut -d':' -f1)!" {output.mvnwk}tmp
            fi
        done < {input.metadata} > {log}
        mv {output.mvfna}tmp {output.mvfna}
        mv {output.mvnwk}tmp {output.mvnwk}
        """

rule index_sequences:
    input:
        sequences=rules.rename_tree.output.mvfna
    output:
        indexed_sequences="results/{organism}/trees/auspice/{organism}_{existing_samples}.tsv"
    log: "logs/{organism}/nextstrain/ns_index_{existing_samples}.log"
    shell: "augur index --sequences {input.sequences} --output {output.indexed_sequences}"

rule refine:
    input:
        sequences=rules.rename_tree.output.mvfna,
        metadata=rules.convert_metaxls.output.metadata,
        tree=rules.rename_tree.output.mvnwk
    output:
        tree="results/{organism}/trees/auspice/{existing_samples}_tree.nwk",
        node_data="results/{organism}/trees/auspice/{existing_samples}_branch_lengths.json"
    log: "logs/{organism}/nextstrain/ns_refine_{existing_samples}.log"
    shell:
        """
        augur refine \
        --alignment {input.sequences} \
        --tree {input.tree} \
        --metadata {input.metadata} \
        --output-tree {output.tree} \
        --output-node-data {output.node_data} > /dev/null 2>&1
        """

rule ancestral:
    input:
        tree=rules.refine.output.tree,
        sequences=rules.rename_tree.output.mvfna
    output:
        node_data="results/{organism}/trees/auspice/{existing_samples}_nt_muts.json"
    params:
        inference="joint"
    log: "logs/{organism}/nextstrain/ns_ancestral_{existing_samples}.log"
    shell:
        """
        augur ancestral \
        --tree {input.tree} \
        --alignment {input.sequences} \
        --output-node-data {output.node_data} \
        --inference {params.inference} > /dev/null 2>&1
        """

rule traits:
    input:
        tree=rules.refine.output.tree,
        metadata=rules.convert_metaxls.output.metadata
    output:
        traits="results/{organism}/trees/auspice/{existing_samples}_traits.json"
    params:
        columns="country region"
    log: "logs/{organism}/nextstrain/ns_traits_{existing_samples}.log"
    shell:
        """
        augur traits \
        --tree {input.tree} \
        --metadata {input.metadata} \
        --output-node-data {output.traits} \
        --columns {params.columns} \
        --confidence > /dev/null 2>&1 
        """

rule export:
    input:
        tree=rules.refine.output.tree,
        metadata=rules.convert_metaxls.output.metadata,
        branch_lengths=rules.refine.output.node_data,
        traits=rules.traits.output.traits,
        nt_muts=rules.ancestral.output.node_data,
        colors="config/auspice/colors.tsv",
        lat_longs="config/auspice/lat_longs.tsv",
        auspice_config="config/auspice/auspice_config.json"
    output:
        auspice_json="results/auspice/{organism}_{existing_samples}_auspice.json"
    log: "logs/{organism}/nextstrain/ns_export_{existing_samples}.log"
    shell:
        """
        augur export v2 \
        --tree {input.tree} \
        --metadata {input.metadata} \
        --node-data {input.branch_lengths} {input.traits} {input.nt_muts} \
        --colors {input.colors} \
        --lat-longs {input.lat_longs} \
        --auspice-config {input.auspice_config} \
        --include-root-sequence \
        --output {output.auspice_json} > /dev/null 2>&1
        """