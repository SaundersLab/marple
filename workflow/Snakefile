import glob
import os

configfile: "config/config.yml"

samples = {}
for fastq in glob.glob('reads/*/*.fastq.gz'):
    organism = fastq.split('/')[1]
    sample = os.path.basename(fastq)[:-len('.fastq.gz')]
    samples[organism] = samples.get(organism, []) + [sample]

bwa_index_extensions = [".amb", ".ann", ".bwt", ".pac", ".sa"]

wildcard_constraints:
    organism="(pst)|(pgt)",
    existing_samples="(all)|(subset)"

rule all:
    input:
        t="results/pgt/trees/pgt_subset.pdf"
        # cons="results/pgt/fiction1/aligned/fiction1.ffn"
        # tree="results/pst/trees/pst_subset.pdf",
        # flat="results/pst/norfolk1/tree_input/norfolk1.ffn",
        # report="results/pst/norfolk1/fastqc_filtered_reads/norfolk1_fastqc.html",
        # flagstat="results/pst/norfolk1/flagstat/norfolk1.txt",
        # mqc="results/pst/report/pst.multiqc.html",

rule bwa_index:
    input: "resources/{organism}/reference/{organism}.fna"
    output:
        multiext(
            "resources/{organism}/reference/{organism}.fna",
            *bwa_index_extensions
        )
    conda: "envs/bwa_samtools.yml"
    log: "logs/{organism}/bwa_index.log"
    shell: "bwa index {input} >{log} 2>&1"

rule bwa_mem:
    input:
        ref="resources/{organism}/reference/{organism}.fna",
        idx=multiext(
            "resources/{organism}/reference/{organism}.fna",
            *bwa_index_extensions
        ),
        fastq="results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz",
    output: "results/{organism}/{sample}/aligned/{sample}.bam"
    conda: "envs/bwa_samtools.yml"
    log: "logs/{organism}/{sample}/bwa_mem_{sample}.log"
    threads: config["bwa_mem_threads"]
    shell: """
    (
        bwa mem -t {threads} {input.ref} {input.fastq} | samtools sort > {output}
    ) >{log} 2>&1
    """

rule samtools_index:
    input: "resources/{organism}/reference/{organism}.fna"
    output: "resources/{organism}/reference/{organism}.fna.fai"
    log: "logs/{organism}/samtools_index.log"
    conda: "envs/bwa_samtools.yml"
    shell: "samtools faidx {input} >{output} 2>{log}"

rule filter_reads:
    input: "reads/{organism}/{sample}.fastq.gz"
    output: "results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz"
    log: "logs/{organism}/{sample}/filter_reads_{sample}.log"
    conda: "envs/nanoq.yml"
    shell: """
        nanoq \
            -m {config[maximum_read_length]} \
            -q {config[minimum_average_read_quality]} \
            -i {input} \
            -o {output} \
            >{log} 2>&1
    """

rule fastqc:
    input: "reads/{organism}/{sample}.fastq.gz"
    output:
        html="results/{organism}/{sample}/fastqc/{sample}_fastqc.html",
        data="results/{organism}/{sample}/fastqc/{sample}_fastqc.zip",
    log: "logs/{organism}/{sample}/fastqc_{sample}.log"
    conda: "envs/fastqc.yml"
    shell: "fastqc -o $(dirname {output.html}) {input} >{log} 2>&1"

use rule fastqc as fastqc_filtered_reads with:
    input: "results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz"
    output:
        html="results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.html",
        data="results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.zip"
    log: "logs/{organism}/{sample}/fastqc_filtered_reads_{sample}.log"

rule flagstat:
    input: "results/{organism}/{sample}/aligned/{sample}.bam"
    output: "results/{organism}/{sample}/flagstat/{sample}.txt"
    log: "logs/{organism}/{sample}/flagstat_{sample}.log"
    conda: "envs/bwa_samtools.yml"
    shell: "samtools flagstat {input} >{output} 2>{log}"

def multiqc_input(wildcards):
    organism = wildcards.organism
    files = [
        f"results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.zip"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/flagstat/{sample}.txt"
        for sample in samples[organism]
    ]
    return files

rule multiqc:
    input: multiqc_input
    output: "results/{organism}/report/{organism}.multiqc.html",
    log: "logs/{organism}/multiqc_{organism}.log",
    conda: "envs/multiqc.yml"
    shell: "multiqc -f {input} -n {output} >{log} 2>&1"

rule pileup:
    input:
        ref="resources/{organism}/reference/{organism}.fna",
        idx="resources/{organism}/reference/{organism}.fna.fai",
        bam="results/{organism}/{sample}/aligned/{sample}.bam",
    output: "results/{organism}/{sample}/aligned/{sample}.pileup.gz"
    log: "logs/{organism}/{sample}/pileup_{sample}.log"
    conda: "envs/bwa_samtools.yml"
    shell: "(samtools mpileup -f {input.ref} {input.bam} | gzip -c > {output}) >{log} 2>&1"

rule consensus:
    input:
        pileup="results/{organism}/{sample}/aligned/{sample}.pileup.gz",
        ref="resources/{organism}/reference/{organism}.fna",
    output: 
        consensus="results/{organism}/{sample}/aligned/{sample}.fna",
        snps="results/{organism}/{sample}/snps/{sample}.tsv"
    log: "logs/{organism}/{sample}/consensus_{sample}.log"
    conda: "envs/biopython_pandas.yml"
    script: "scripts/pileup_to_consensus.py"

rule extract_cds:
    input: 
        consensus="results/{organism}/{sample}/aligned/{sample}.fna",
        gff="resources/{organism}/reference/{organism}.gff",
    output: "results/{organism}/{sample}/aligned/{sample}.ffn"
    log: "logs/{organism}/{sample}/extract_cds_{sample}.log"
    conda: "envs/gffread.yml"
    shell: "gffread -x {output} -g {input.consensus} {input.gff} >{log} 2>&1"

rule flatten:
    input: "results/{organism}/{sample}/aligned/{sample}.ffn"
    output: "results/{organism}/{sample}/tree_input/{sample}.ffn"
    log: "logs/{organism}/{sample}/flatten_{sample}.log"
    shell: 
        """
        echo \>{wildcards.sample} > {output}
        grep -v \> {input} | tr -d '\n' >> {output}
        echo >> {output}
        """

def tree_input_files_to_merge(wildcards):
    organism = wildcards.organism
    return [
        f"results/{organism}/{sample}/tree_input/{sample}.ffn"
        for sample in samples[organism]
    ]

rule merge:
    input:
        existing_samples="resources/{organism}/{organism}_{existing_samples}.ffn.gz",
        new_samples=tree_input_files_to_merge
    output: "results/{organism}/trees/{organism}_{existing_samples}.ffn",
    log: "logs/{organism}/trees/merge_{existing_samples}.log",
    shell:
        """
        (cat {input.new_samples} > {output}
        gzcat {input.existing_samples} >> {output}) >{log}
        """

rule tree:
    input: "results/{organism}/trees/{organism}_{existing_samples}.ffn"
    output: "results/{organism}/trees/{organism}_{existing_samples}.newick"
    log: "logs/{organism}/trees/tree_{existing_samples}.log"
    conda: "envs/raxml-ng.yml"
    threads: 2
    shell: "workflow/scripts/raxml-ng.sh {input} {output} {threads} >{log} 2>&1"

rule visualise_tree:
    input:
        tree="results/{organism}/trees/{organism}_{existing_samples}.newick",
        metadata="resources/{organism}/{organism}_sample_metadata.xlsx"
    output: "results/{organism}/trees/{organism}_{existing_samples}.pdf"
    log: "logs/{organism}/trees/visualise_tree_{existing_samples}.log"
    conda: "envs/visualise_tree.yml"
    script: "scripts/visualise_tree.py"



