import os
import glob

configfile: "config/config.yml"

samples = {}
for fastq in glob.glob('reads/*/*.fastq.gz'):
    organism = fastq.split('/')[1]
    sample = os.path.basename(fastq)[:-len('.fastq.gz')]
    samples[organism] = samples.get(organism, []) + [sample]

bwa_index_extensions = [".amb", ".ann", ".bwt", ".pac", ".sa"]

wildcard_constraints:
    organism="(pst)|(pgt)",
    existing_samples="(all)|(subset)"

def all_inputs(wildcards):
    inputs = {}
    for organism in samples:
        inputs[f'{organism}_tree'] = f'results/{organism}/trees/{organism}_all.pdf'
        inputs[f'{organism}_report'] = f'results/{organism}/report/{organism}.multiqc.html'
    return inputs

rule all:
    input:
        unpack(all_inputs)

def primer_performance_summaries(wildcards):
    organism = wildcards.organism
    sample = wildcards.sample
    return [
        f"results/{organism}/{sample}/primer_performance/{sample}_primer_performance_by_{groupby}.csv"
        for groupby in config['primer_performance_groups']
        ]

rule create_sample_multiqc_row:
    input:
        tree_input="results/{organism}/{sample}/tree_input/{sample}.ffn",
        primer_performance_summaries=primer_performance_summaries
    output: 
        multiqc_row="results/{organism}/{sample}/multiqc_row/{sample}_multiqc_row.csv"
    log: "logs/{organism}/{sample}/create_sample_multiqc_row_{sample}.log"
    script: "scripts/create_sample_multiqc_row.py"

rule create_fung_vir_multiqc_row:
# Change organism as above when Pst integration is ready to run for both
    input:
        consensus="results/pgt/{sample}/aligned/{sample}.fna",
        metadata="resources/fungicide_metadata.xlsx",
        reference="resources/pgt/reference/pgt.fna",
    output: 
        multiqc_fung="results/pgt/{sample}/multiqc_row/{sample}_multiqc_fung_table.csv",
        multiqc_rgene="results/pgt/{sample}/multiqc_row/{sample}_multiqc_rgene_table.csv",
        multiqc_avr="results/pgt/{sample}/multiqc_row/{sample}_multiqc_avrgene_table.csv"
    log: "logs/pgt/{sample}/create_fung_vir_multiqc_row_{sample}.log"
    script: "scripts/virulence_fungicide_multiqc_row.py"

rule summarise_primer_performance:
    input:
        primer_performance="results/{organism}/{sample}/primer_performance/{sample}_primer_performance.csv"
    output:
        primer_performance_summary="results/{organism}/{sample}/primer_performance/{sample}_primer_performance_by_{groupby}.csv"
    log: "logs/{organism}/{sample}/summarise_primer_performance_by_{groupby}_{sample}.log"
    script: "scripts/summarise_primer_performance.py" 

rule cumulative_amplicon_coverage:
    input:
        primer_performance="results/{organism}/{sample}/primer_performance/{sample}_primer_performance.csv"
    output:
        cumulative_amplicon_coverage="results/{organism}/{sample}/primer_performance/{sample}_cumulative_amplicon_coverage.csv"
    log: "logs/{organism}/{sample}/cumulative_amplicon_coverage_{sample}.log"
    script: "scripts/cumulative_amplicon_coverage.py"

# This is a work around to ensure that multiqc can create the plot specified in
# config/multiqc_config.yaml.
# Unless there is at least one _mqc.yaml in the directory, multiqc will not 
# pick up any of the custom_data specified in the --config file. To ensure it
# does pick up those files, we create a file for each sample with only id.
rule placeholder_mqc:
    output: 
        placeholder_mqc="results/{organism}/{sample}/primer_performance/{sample}_empty_config_required_for_amplicon_coverage_mqc.yaml"
    log: "logs/{organism}/{sample}/placeholder_mqc_{sample}.log"
    script: "scripts/create_empty_config_required_for_amplicon_coverage_mqc.py"

def snp_tables_to_summaries(wildcards):
    organism = wildcards.organism
    return [
        f"results/{organism}/{sample}/snps/{sample}.tsv"
        for sample in samples[organism]
    ]

rule summarise_snps:
    input:
        ref="resources/{organism}/reference/{organism}.fna",
        snps=snp_tables_to_summaries
    output:
        snp_counts="results/{organism}/report/snp_summary.csv"
    log: "logs/{organism}/summarise_snps.log"
    script: "scripts/summarise_snps_by_gene.py"

types = ['fung', 'rgene', 'avrgene']

def fung_virulence_files(wildcards):
    files = [
        f"results/pgt/{sample}/multiqc_row/{sample}_multiqc_{wildcards.types}_table.csv"
        for sample in samples['pgt']
    ]
    return files

rule summarise_virs:
    input:
        fungin=expand("results/pgt/{sample}/multiqc_row/{sample}_multiqc_fung_table.csv", sample=samples['pgt']) if 'pgt' in samples else '',
        srin=expand("results/pgt/{sample}/multiqc_row/{sample}_multiqc_rgene_table.csv", sample=samples['pgt']) if 'pgt' in samples else '',
        avrin=expand("results/pgt/{sample}/multiqc_row/{sample}_multiqc_avrgene_table.csv", sample=samples['pgt']) if 'pgt' in samples else ''
    output:
        fungout="results/pgt/report/fung_summary.csv",
        srout="results/pgt/report/rgene_summary.csv",
        avrout="results/pgt/report/avr_summary.csv"
    log: "logs/pgt/summarise_fungs.log"
    run:
        input_files = input.fungin + input.srin + input.avrin
        if all(os.path.exists(f) for f in input_files):
            shell("""
            python -c "
import re
import pandas as pd
input_files = ['{input.fungin}','{input.srin}','{input.avrin}']
output_files = ['{output.fungout}','{output.srout}','{output.avrout}']
for files, fout in zip(input_files, output_files):
    file_list = re.sub('\\s+', ',', files).split(',')
    df_list = [pd.read_csv(f) for f in file_list if len(open(f, 'r').readlines()) > 1]
    if df_list:
        df_final = pd.concat(df_list, axis=0, ignore_index=True, sort=False)
        df_final.to_csv(fout, index=True, index_label='index')
    if not df_list:
        open(fout, 'x')
            " 2> {log}
            """)
        else:
            print("Skipping summarise_virs because input files do not exist.")


rule primer_performance:
    input:
        pileup="results/{organism}/{sample}/aligned/{sample}.pileup.gz",
        primers="resources/{organism}/{organism}_primer_metadata.csv",
        consensus="results/{organism}/{sample}/aligned/{sample}.fna",
    output:
        primer_performance="results/{organism}/{sample}/primer_performance/{sample}_primer_performance.csv"
    log: "logs/{organism}/{sample}/primer_performance_{sample}.log"
    script: "scripts/primer_performance.py"

rule bwa_index:
    input: "resources/{organism}/reference/{organism}.fna"
    output:
        multiext(
            "resources/{organism}/reference/{organism}.fna",
            *bwa_index_extensions
        )
    log: "logs/{organism}/bwa_index.log"
    shell:"bwa index {input} >{log} 2>&1"

rule bwa_mem:
    input:
        ref="resources/{organism}/reference/{organism}.fna",
        idx=multiext(
            "resources/{organism}/reference/{organism}.fna",
            *bwa_index_extensions
        ),
        fastq="results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz",
    output: "results/{organism}/{sample}/aligned/{sample}.bam"
    log: "logs/{organism}/{sample}/bwa_mem_{sample}.log"
    threads: config["bwa_mem_threads"]
    shell: """
    (
        bwa mem -t {threads} {input.ref} {input.fastq} | samtools sort > {output};
        samtools index {output}
    ) >{log} 2>&1
    """

rule samtools_index:
    input: "resources/{organism}/reference/{organism}.fna"
    output: "resources/{organism}/reference/{organism}.fna.fai"
    log: "logs/{organism}/samtools_index.log"
    shell: "samtools faidx {input} >{output} 2>{log}"

rule filter_reads:
    input: "reads/{organism}/{sample}.fastq.gz"
    output: "results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz"
    log: "logs/{organism}/{sample}/filter_reads_{sample}.log"
    shell: """
        nanoq \
            -m {config[maximum_read_length]} \
            -q {config[minimum_average_read_quality]} \
            -i {input} \
            -o {output} \
            >{log} 2>&1
    """

rule fastqc:
    input: "reads/{organism}/{sample}.fastq.gz"
    output:
        html="results/{organism}/{sample}/fastqc/{sample}_fastqc.html",
        data="results/{organism}/{sample}/fastqc/{sample}_fastqc.zip",
    log: "logs/{organism}/{sample}/fastqc_{sample}.log"
    shell: "fastqc -o $(dirname {output.html}) {input} >{log} 2>&1"

use rule fastqc as fastqc_filtered_reads with:
    input: "results/{organism}/{sample}/filtered_reads/{sample}.fastq.gz"
    output:
        html="results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.html",
        data="results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.zip"
    log: "logs/{organism}/{sample}/fastqc_filtered_reads_{sample}.log"

rule flagstat:
    input: "results/{organism}/{sample}/aligned/{sample}.bam"
    output: "results/{organism}/{sample}/flagstat/{sample}.txt"
    log: "logs/{organism}/{sample}/flagstat_{sample}.log"
    shell: "samtools flagstat {input} >{output} 2>{log}"

def multiqc_input(wildcards):
    organism = wildcards.organism
    files = [
        f"results/{organism}/{sample}/fastqc_filtered_reads/{sample}_fastqc.zip"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/flagstat/{sample}.txt"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/primer_performance/{sample}_cumulative_amplicon_coverage.csv"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/primer_performance/{sample}_empty_config_required_for_amplicon_coverage_mqc.yaml"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/{sample}/multiqc_row/{sample}_multiqc_row.csv"
        for sample in samples[organism]
    ]
    files += [
        f"results/{organism}/report/snp_summary.csv"
    ]
    if wildcards.organism == 'pgt':
        files += [
            "results/pgt/report/fung_summary.csv"
        ]
        files += [
            "results/pgt/report/rgene_summary.csv"
        ]
        files += [
            "results/pgt/report/avr_summary.csv"
            ]
    return files

rule multiqc:
    input: multiqc_input
    output: "results/{organism}/report/{organism}.multiqc.html",
    log: "logs/{organism}/multiqc_{organism}.log",
    shell: """
        tempdir=$(mktemp -d)
        cp {input} $tempdir
        multiqc -f $tempdir --config config/multiqc_config.yml -n {output} >{log} 2>&1
        rm -r $tempdir
    """

rule pileup:
    input:
        ref="resources/{organism}/reference/{organism}.fna",
        idx="resources/{organism}/reference/{organism}.fna.fai",
        bam="results/{organism}/{sample}/aligned/{sample}.bam",
    output: "results/{organism}/{sample}/aligned/{sample}.pileup.gz"
    log: "logs/{organism}/{sample}/pileup_{sample}.log"
    shell: "(samtools mpileup -f {input.ref} {input.bam} | gzip -c > {output}) >{log} 2>&1"

rule consensus:
    input:
        pileup="results/{organism}/{sample}/aligned/{sample}.pileup.gz",
        ref="resources/{organism}/reference/{organism}.fna",
    output: 
        consensus="results/{organism}/{sample}/aligned/{sample}.fna",
        snps="results/{organism}/{sample}/snps/{sample}.tsv"
    log: "logs/{organism}/{sample}/consensus_{sample}.log"
    script: "scripts/pileup_to_consensus.py"

rule extract_cds:
    input: 
        consensus="results/{organism}/{sample}/aligned/{sample}.fna",
        gff="resources/{organism}/reference/{organism}.gff",
    output: "results/{organism}/{sample}/aligned/{sample}.ffn"
    log: "logs/{organism}/{sample}/extract_cds_{sample}.log"
    shell: "gffread -x {output} -g {input.consensus} {input.gff} >{log} 2>&1"

rule flatten:
    input: "results/{organism}/{sample}/aligned/{sample}.ffn"
    output: "results/{organism}/{sample}/tree_input/{sample}.ffn"
    log: "logs/{organism}/{sample}/flatten_{sample}.log"
    shell: 
        """
        echo \\>{wildcards.sample} > {output}
        grep -v \\> {input} | tr -d '\n' >> {output}
        echo >> {output}
        """

def tree_input_files_to_merge(wildcards):
    organism = wildcards.organism
    return [
        f"results/{organism}/{sample}/tree_input/{sample}.ffn"
        for sample in samples[organism]
    ]

rule merge:
    input:
        existing_samples="resources/{organism}/{organism}_{existing_samples}.ffn.gz",
        new_samples=tree_input_files_to_merge
    output: "results/{organism}/trees/{organism}_{existing_samples}.ffn",
    log: "logs/{organism}/trees/merge_{existing_samples}.log",
    shell:
        """
        (cat {input.new_samples} > {output}
        gunzip -c {input.existing_samples} >> {output}) >{log}
        """

rule tree:
    input: "results/{organism}/trees/{organism}_{existing_samples}.ffn"
    output: "results/{organism}/trees/{organism}_{existing_samples}.nwk"
    log: "logs/{organism}/trees/tree_{existing_samples}.log"
    shell: "workflow/scripts/fasttree.sh {input} {output} >{log} 2>&1"

rule visualise_tree:
    input:
        tree="results/{organism}/trees/{organism}_{existing_samples}.nwk",
        metadata="resources/{organism}/{organism}_sample_metadata.xlsx"
    output: "results/{organism}/trees/{organism}_{existing_samples}.pdf"
    log: "logs/{organism}/trees/visualise_tree_{existing_samples}.log"
    script: "scripts/visualise_tree.py"
